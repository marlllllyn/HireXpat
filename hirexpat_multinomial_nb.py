# -*- coding: utf-8 -*-
"""HireXpat Multinomial NB.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xoJzctOVw3WsV1UfZD4oEYwZdI86feZs
"""

# IMPORT
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
import pickle
import numpy as np

df = pd.read_csv('buattrain.csv',
                 sep=';',
                 low_memory = False)
#df.sample(100)

# DATA CLEANING
df['description'] = df['description'].map(str) #mapping to str
df['description'] = df['description'].str.lower() #lowering all case
df['description'] = df['description'].str.replace(r'[^\w\s]+', ' ') #remove Punct
df['description'] = df['description'].str.replace(r'_+', ' ') #remove Punct
df['description'] = df['description'].str.replace('\s+', ' ', regex=True) #remove multiple space

#DIVIDING DATA INPUT & OUTPUT
input_column  = 'description'
output_column = 'label'
X = df.loc[:,input_column]
y = df.loc[:,output_column]
print('Data Divided Successfully Into Input & Output')

#BAG OF WORDS MODEL TO CONVERT FEATURES INTO NUMBERS
from sklearn.feature_extraction.text import CountVectorizer
count_vect = CountVectorizer()
X_counts   = count_vect.fit_transform(X).toarray()
print(X_counts.shape)

#TRAIN - TEST DATA SPLIT
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_counts, y, test_size=0.1, random_state=0)
print('Data Divided Into Train & Test')

#CLASSIFICATION USING NAIVE BAYES
import numpy as np
from sklearn.naive_bayes import MultinomialNB
clf = MultinomialNB().fit(X_train, y_train)

predict = clf.predict(X_test)
print('Accuracy of The Model is =====> '+str(round(np.mean(predict == y_test)*100,2))+'%')

import pickle

# Save the trained model
with open('naive_bayes_model.pkl', 'wb') as f:
    pickle.dump(clf, f)

with open('count_vectorizer.pkl', 'wb') as f:
    pickle.dump(count_vect, f)


from google.colab import files
files.download('count_vectorizer.pkl')
files.download('naive_bayes_model.pkl')

"""API LOGIC"""

# import pickle
# import re

# # Load the trained model
# with open('naive_bayes_model.pkl', 'rb') as f:
#     model = pickle.load(f)

# # Load the CountVectorizer
# with open('count_vectorizer.pkl', 'rb') as f:
#     count_vect = pickle.load(f)

# # Inputan
# text = 'A skilled insurance test.'

# # Preprocess the input text
# text = text.lower()
# text = re.sub(r'[^\w\s]+', ' ', text)
# text = re.sub(r'_+', ' ', text)
# text = re.sub('\s+', ' ', text)

# # Vectorize the input text
# text_vectorized = count_vect.transform([text])

# # Make the prediction
# predicted_probabilities = model.predict_proba(text_vectorized)[0]
# top_class_index = predicted_probabilities.argmax()
# top_class = model.classes_[top_class_index]
# top_probability = predicted_probabilities[top_class_index]

# from flask import Flask, request, jsonify, make_response
# import pandas as pd

# data_companies = pd.read_csv('data_company.csv',sep=';',low_memory=False)
# df = pd.DataFrame(data_companies)
# df.head(5)

# list_job = []
# for i in range(len(df)):
#   if df['industry'][i] == top_class:
#     list_job.append(df.iloc[i])


# response = {
#     'predictions':
#         {'class': top_class, 'probability': top_probability},
#     'list_job': list_job
# }

"""FILE API, ENDPOINT: /listjob, METHOD: POST, REQUREST BODY: {"description": "Bio User"}, RESPONSE BODY: {"prediction": "Insurance", "list_job": array object dari row data_company}"""

# from flask import Flask, request, jsonify, make_response
# from flask_cors import CORS
# import pickle
# import re
# import uuid
# from datetime import datetime
# import pandas as pd

# app = Flask(__name__)
# CORS(app)

# # Load the trained model
# with open('naive_bayes_model.pkl', 'rb') as f:
#     model = pickle.load(f)

# # Load the CountVectorizer
# with open('count_vectorizer.pkl', 'rb') as f:
#     count_vect = pickle.load(f)


# @app.route('/listjob', methods=['POST'])
# def predict():
#     try:
#         # Request Body
#         data = request.json
#         text = data['description']

#         # Preprocess the input text
#         text = text.lower()
#         text = re.sub(r'[^\w\s]+', ' ', text)
#         text = re.sub(r'_+', ' ', text)
#         text = re.sub('\s+', ' ', text)

#         # Vectorize the input text
#         text_vectorized = count_vect.transform([text])

#         # Make the prediction
#         predicted_probabilities = model.predict_proba(text_vectorized)[0]
#         top_class_index = predicted_probabilities.argmax()
#         top_class = model.classes_[top_class_index]
#         top_probability = predicted_probabilities[top_class_index]

#         data_companies = pd.read_csv('data_company.csv',sep=',',low_memory=False)
#         df = pd.DataFrame(data_companies)

#         list_job = []
#         for i in range(len(df)):
#           if df['industry'][i] == top_class:
#             list_job.append(df.iloc[i])


#         response = {
#             'prediction': top_class,
#             'list_job': list_job
#         }

#         return jsonify(response)
#     except Exception as error:
#         error_message = f"Prediction error: {str(error)}"
#         response = make_response(jsonify({'error': error_message}), 500)
#         return response

# if __name__ == '__main__':
#     app.run()

# from flask import Flask, request, jsonify, make_response
# from flask_cors import CORS
# import pickle
# import re
# import uuid
# from datetime import datetime
# import pandas as pd

# app = Flask(__name__)
# CORS(app)

# # Load the trained model
# with open('naive_bayes_model.pkl', 'rb') as f:
#     model = pickle.load(f)

# # Load the CountVectorizer
# with open('count_vectorizer.pkl', 'rb') as f:
#     count_vect = pickle.load(f)

# @app.route('/listjob', methods=['POST'])
# def predict():
#     try:
#         # Request Body
#         data = request.json
#         text = data['description']

#         # Preprocess the input text
#         text = text.lower()
#         text = re.sub(r'[^\w\s]+', ' ', text)
#         text = re.sub(r'_+', ' ', text)
#         text = re.sub('\s+', ' ', text)

#         # Vectorize the input text
#         text_vectorized = count_vect.transform([text])

#         # Make the prediction
#         predicted_probabilities = model.predict_proba(text_vectorized)[0]
#         top_class_index = predicted_probabilities.argmax()
#         top_class = model.classes_[top_class_index]
#         top_probability = predicted_probabilities[top_class_index]

#         data_companies = pd.read_csv('data_company.csv', sep=';', low_memory=False)
#         df = pd.DataFrame(data_companies)

#         # Filter DataFrame and convert to list of dictionaries
#         list_job = df[df['industry'] == top_class].to_dict(orient='records')

#         response = {
#             'prediction': top_class,
#             'list_job': list_job
#         }

#         return jsonify(response)
#     except Exception as error:
#         error_message = f"Prediction error: {str(error)}"
#         response = make_response(jsonify({'error': error_message}), 500)
#         return response

# if __name__ == '__main__':
#     app.run()